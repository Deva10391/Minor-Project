{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import shap\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"model.pkl\", \"rb\") as f:\n",
    "    model = pickle.load(f)\n",
    "\n",
    "with open(\"explainer.pkl\", \"rb\") as f:\n",
    "    explainer = pickle.load(f)\n",
    "\n",
    "def predict(data_list):\n",
    "    y_pred_test=model.predict([data_list])\n",
    "    return y_pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare(data_list):\n",
    "    prev_data_frame = pd.DataFrame(data_list)\n",
    "    data_frame=prev_data_frame.transpose().values[0]\n",
    "\n",
    "    feature_names=[]\n",
    "    for i in prev_data_frame.transpose():\n",
    "        feature_names.append(i)\n",
    "    \n",
    "    explainer = shap.TreeExplainer(model)\n",
    "    shap_values = explainer.shap_values(data_frame, check_additivity=False)\n",
    "    shap_values = shap_values.transpose()\n",
    "    \n",
    "    return {'data_frame': data_frame, 'shap_values': shap_values, 'feature_names': feature_names}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_shap(data_list):\n",
    "    \n",
    "    data_frame=pd.DataFrame(data_list)\n",
    "    explainer = shap.TreeExplainer(model)\n",
    "    prev_shap_values = explainer.shap_values(data_frame, check_additivity=False)\n",
    "    shap_values = prev_shap_values.transpose()\n",
    "\n",
    "    index=0\n",
    "    feature_importances = np.abs(shap_values).mean(axis=0)\n",
    "    sorted_features = np.sort(feature_importances[0])[::-1]\n",
    "    max_shap=sorted_features[0]\n",
    "\n",
    "    print(f\"row {i} is safe mainly because> \", end='')\n",
    "    \n",
    "    for i in range (0, len(feature_importances[0])):\n",
    "        if(feature_importances[0][i]==max_shap):\n",
    "            print(f\"column index {i}\", end=' ')\n",
    "            index=i\n",
    "    \n",
    "    data_point = data_frame.iloc[index]\n",
    "    print(f\"is: {data_point[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_importance_ranking(data_list):\n",
    "  \n",
    "  shap_values = prepare(data_list)['shap_values']\n",
    "  feature_names = prepare(data_list)['feature_names']\n",
    "  \n",
    "  feature_importances = np.abs(shap_values).mean(axis=0)\n",
    "\n",
    "  importance_df = pd.DataFrame({'feature': feature_names, 'importance': feature_importances})\n",
    "\n",
    "  importance_df.sort_values(by='importance', ascending=False, inplace=True)\n",
    "\n",
    "  arr=np.around(importance_df, decimals=4)\n",
    "  print(arr.transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_shap_value_distribution(data_list):\n",
    "    \n",
    "  shap_values = prepare(data_list)['shap_values']\n",
    "  feature_names = prepare(data_list)['feature_names']\n",
    "    \n",
    "  for i in range(shap_values.shape[1]):\n",
    "    plt.hist(shap_values[:, i])\n",
    "    plt.xlabel(\"SHAP Value\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.title(f\"Distribution of SHAP Values for {feature_names[i]}\")\n",
    "    plt.show()\n",
    "    plt.clf()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explain_individual_datapoint(data_list):\n",
    "    \n",
    "  shap_values = prepare(data_list)['shap_values']\n",
    "  feature_names = prepare(data_list)['feature_names']\n",
    "  \n",
    "  for feature_name, shap_value in zip(feature_names, shap_values[0]):\n",
    "    print(f\"Feature: {feature_name}, SHAP Value: {shap_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 14       10       12      4       7        11      9   \\\n",
      "feature     14.0000  10.0000  12.0000  4.0000  7.0000  11.0000  9.0000   \n",
      "importance   0.2249   0.1668   0.0445  0.0414  0.0343   0.0195  0.0159   \n",
      "\n",
      "                0        16       27  ...      2        28      8        29  \\\n",
      "feature     0.0000  16.0000  27.0000  ...  2.0000  28.0000  8.0000  29.0000   \n",
      "importance  0.0141   0.0129   0.0107  ...  0.0019   0.0018  0.0017   0.0016   \n",
      "\n",
      "                 24       19       23       25       20       21  \n",
      "feature     24.0000  19.0000  23.0000  25.0000  20.0000  21.0000  \n",
      "importance   0.0015   0.0009   0.0008   0.0008   0.0005   0.0004  \n",
      "\n",
      "[2 rows x 30 columns]\n",
      "                12       14       17       11       10      4       9   \\\n",
      "feature     12.000  14.0000  17.0000  11.0000  10.0000  4.0000  9.0000   \n",
      "importance   0.233   0.1846   0.1637   0.1047   0.0895  0.0422  0.0266   \n",
      "\n",
      "                7        26     20  ...      5        22      13      8   \\\n",
      "feature     7.0000  26.0000  20.00  ...  5.0000  22.0000  13.000  8.0000   \n",
      "importance  0.0136   0.0108   0.01  ...  0.0023   0.0022   0.002  0.0011   \n",
      "\n",
      "               0       19       28       23       25       29  \n",
      "feature     0.000  19.000  28.0000  23.0000  25.0000  29.0000  \n",
      "importance  0.001   0.001   0.0009   0.0006   0.0003   0.0003  \n",
      "\n",
      "[2 rows x 30 columns]\n",
      "                 12       14       11       10      9       4       7   \\\n",
      "feature     12.0000  14.0000  11.0000  10.0000  9.0000  4.0000  7.0000   \n",
      "importance   0.2756   0.2091   0.1516   0.0977  0.0517  0.0494  0.0172   \n",
      "\n",
      "                6        16       26  ...       17       22       13       19  \\\n",
      "feature     6.0000  16.0000  26.0000  ...  17.0000  22.0000  13.0000  19.0000   \n",
      "importance  0.0142   0.0124   0.0124  ...   0.0023   0.0022   0.0011   0.0011   \n",
      "\n",
      "                 23       29       18       28      8        25  \n",
      "feature     23.0000  29.0000  18.0000  28.0000  8.0000  25.0000  \n",
      "importance   0.0007   0.0006   0.0004   0.0003  0.0001   0.0001  \n",
      "\n",
      "[2 rows x 30 columns]\n",
      "                 12       14       11       10      9       4       7   \\\n",
      "feature     12.0000  14.0000  11.0000  10.0000  9.0000  4.0000  7.0000   \n",
      "importance   0.2845   0.2056   0.1469   0.0972  0.0488  0.0481  0.0176   \n",
      "\n",
      "                6        26      20  ...       15       29       13       22  \\\n",
      "feature     6.0000  26.0000  20.000  ...  15.0000  29.0000  13.0000  22.0000   \n",
      "importance  0.0161   0.0156   0.011  ...   0.0025   0.0025   0.0019   0.0017   \n",
      "\n",
      "                 19       28      8        23       25       18  \n",
      "feature     19.0000  28.0000  8.0000  23.0000  25.0000  18.0000  \n",
      "importance   0.0014   0.0013  0.0008   0.0003   0.0002   0.0002  \n",
      "\n",
      "[2 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "data=pd.read_csv('base files/creditcard_test.csv')\n",
    "data_list = data.values.tolist()\n",
    "i=0\n",
    "for row in data_list:\n",
    "    i=i+1\n",
    "    res=predict(row)\n",
    "    if(res[0]==1):\n",
    "        try:\n",
    "            # show_shap(row)\n",
    "            get_feature_importance_ranking(row)\n",
    "            # plot_shap_value_distribution(row)\n",
    "            # explain_individual_datapoint(row)\n",
    "        except Exception as e:\n",
    "            print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('done')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
