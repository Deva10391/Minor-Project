{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c9dc809",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import time\n",
    "import torch\n",
    "import pickle\n",
    "import joblib\n",
    "import asyncio\n",
    "import websockets\n",
    "import win32evtlog\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "from river.drift import ADWIN\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3e5f1a",
   "metadata": {},
   "source": [
    "**GAN section**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7739e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, noise_dim, out_dim):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(noise_dim, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, out_dim),\n",
    "        )\n",
    "    def forward(self, z):\n",
    "        return self.net(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e10a93a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self, in_dim):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(in_dim, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ac6fda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "df = pd.read_csv(\"base files/creditcard_train.csv\")\n",
    "\n",
    "X = df.drop(columns=[\"Class\"]).values\n",
    "y = df[\"Class\"].values\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_normal = X_scaled[y == 0]\n",
    "X_normal = torch.tensor(X_normal, dtype=torch.float32)\n",
    "y_normal = torch.zeros(len(X_normal))\n",
    "normal_data = X_normal\n",
    "\n",
    "X_fraud = X_scaled[y == 1]\n",
    "X_fraud = torch.tensor(X_fraud, dtype=torch.float32)\n",
    "y_fraud = torch.ones(len(X_fraud))\n",
    "fraud_data = X_fraud\n",
    "\n",
    "X_real = torch.cat([X_normal, X_fraud])\n",
    "y_real = torch.cat([y_normal, y_fraud])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0d9769f",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_dim = 16\n",
    "n_features = X_real.shape[1]\n",
    "G = Generator(noise_dim, n_features).to(device)\n",
    "D = Classifier(n_features).to(device)\n",
    "\n",
    "lr = 1e-5\n",
    "loss_fn = nn.BCELoss()\n",
    "opt_G = optim.Adam(G.parameters(), lr=lr)\n",
    "opt_G_2 = optim.Adam(G.parameters(), lr=lr)\n",
    "opt_D = optim.Adam(D.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d641023a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000: loss_D 0.138, loss_G 3.107                    "
     ]
    }
   ],
   "source": [
    "for epoch in range(10000):\n",
    "    real = fraud_data.to(device)\n",
    "    z = torch.randn(len(real), noise_dim).to(device)\n",
    "    fake = G(z)\n",
    "\n",
    "    D_real = D(real)\n",
    "    D_fake = D(fake.detach())\n",
    "    loss_D = loss_fn(D_real, torch.ones_like(D_real)) + loss_fn(D_fake, torch.zeros_like(D_fake))\n",
    "    opt_D.zero_grad()\n",
    "    loss_D.backward()\n",
    "    opt_D.step()\n",
    "\n",
    "    D_fake = D(fake)\n",
    "    loss_G = loss_fn(D_fake, torch.ones_like(D_fake))\n",
    "    opt_G.zero_grad()\n",
    "    loss_G.backward()\n",
    "    opt_G.step()\n",
    "\n",
    "    print(f\"\\r{epoch+1}: loss_D {loss_D.item():.3f}, loss_G {loss_G.item():.3f}\", end=20*\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c67981c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Synthetic Fraud Data:\n",
      "[[ 0.5172903   0.6042827   0.35832328 ...  0.76952034  0.43773496\n",
      "  -0.48459098]\n",
      " [ 0.49007067  0.5452349   0.31360126 ...  0.7076121   0.39527908\n",
      "  -0.47065982]\n",
      " [ 1.1941773   1.3294133   0.8513359  ...  1.6827614   0.8992215\n",
      "  -1.177026  ]\n",
      " ...\n",
      " [ 0.34244776  0.4226125   0.25303853 ...  0.51284426  0.37447464\n",
      "  -0.34407666]\n",
      " [ 0.81841546  0.9063668   0.5811417  ...  1.1524384   0.61096716\n",
      "  -0.7533277 ]\n",
      " [ 1.7485393   1.9323717   1.2353566  ...  2.4651153   1.2507966\n",
      "  -1.6772698 ]]\n"
     ]
    }
   ],
   "source": [
    "z_synth = torch.randn(len(fraud_data), noise_dim).to(device)\n",
    "synthetic_frauds = G(z_synth).detach().cpu()\n",
    "\n",
    "synthetic_frauds_np = synthetic_frauds.numpy()\n",
    "\n",
    "print(\"Generated Synthetic Fraud Data:\")\n",
    "print(synthetic_frauds_np)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c8bcf614",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_synth = torch.randn(len(fraud_data), noise_dim).to(device)\n",
    "synthetic_frauds = G(z_synth).detach().cpu()\n",
    "synthetic_labels = torch.ones(len(synthetic_frauds))\n",
    "\n",
    "X_aug = torch.cat([X_real, synthetic_frauds])\n",
    "y_aug = torch.cat([y_real, synthetic_labels])\n",
    "\n",
    "C = Classifier(n_features).to(device)\n",
    "opt_C = optim.Adam(C.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6cca05b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100: loss 0.009                    "
     ]
    }
   ],
   "source": [
    "for epoch in range(100):\n",
    "    idx = torch.randperm(len(X_aug))\n",
    "    x_batch = X_aug[idx].to(device)\n",
    "    y_batch = y_aug[idx].unsqueeze(1).to(device)\n",
    "\n",
    "    y_pred = C(x_batch)\n",
    "    loss = loss_fn(y_pred, y_batch)\n",
    "    opt_C.zero_grad()\n",
    "    loss.backward()\n",
    "    opt_C.step()\n",
    "\n",
    "    print(f\"\\r{epoch+1}: loss {loss.item():.3f}\", end=20*\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cfc5da4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1512: loss_C 0.000, loss_G 19.255                    "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m loss_C \u001b[38;5;241m=\u001b[39m loss_fn(preds, labels)\n\u001b[0;32m      8\u001b[0m opt_C\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m----> 9\u001b[0m \u001b[43mloss_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m opt_C\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     12\u001b[0m preds \u001b[38;5;241m=\u001b[39m C(fake_frauds)\n",
      "File \u001b[1;32mc:\\Users\\devas\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\_tensor.py:521\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    513\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    514\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    519\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    520\u001b[0m     )\n\u001b[1;32m--> 521\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\devas\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\autograd\\__init__.py:289\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    284\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    286\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 289\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    297\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\devas\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\autograd\\graph.py:769\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    767\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    768\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 769\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    770\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    771\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    772\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    773\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(2000):\n",
    "    z = torch.randn(len(fraud_data), noise_dim).to(device)\n",
    "    fake_frauds = G(z)\n",
    "\n",
    "    labels = torch.ones(len(fake_frauds), 1).to(device)\n",
    "    preds = C(fake_frauds)\n",
    "    loss_C = loss_fn(preds, labels)\n",
    "    opt_C.zero_grad()\n",
    "    loss_C.backward(retain_graph=True)\n",
    "    opt_C.step()\n",
    "\n",
    "    preds = C(fake_frauds)\n",
    "    loss_G = loss_fn(preds, torch.zeros_like(preds))\n",
    "    opt_G.zero_grad()\n",
    "    loss_G.backward()\n",
    "    opt_G.step()\n",
    "\n",
    "    print(f\"\\r{epoch+1}: loss_C {loss_C.item():.3f}, loss_G {loss_G.item():.3f}\", end=20*\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c0c92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(G.state_dict(), 'fraud_detection_G.pth')\n",
    "torch.save(D.state_dict(), 'fraud_detection_D.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e3ee3c",
   "metadata": {},
   "source": [
    "**online-Learning section**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d93a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('base files/creditcard_train.csv')\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "X_all = df.drop(columns=['Class'])\n",
    "y_all = df['Class'].values\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_all = scaler.fit_transform(X_all)\n",
    "\n",
    "model = SGDClassifier(loss='log_loss', max_iter=1, warm_start=True)\n",
    "model.partial_fit(X_all[:1000], y_all[:1000], classes=np.array([0, 1]))\n",
    "\n",
    "adwin = ADWIN()\n",
    "uncertainty_threshold = 0.3\n",
    "window_size = 500\n",
    "threshold_drop = 0.05\n",
    "\n",
    "recent_accuracies = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1000, len(X_all)):\n",
    "    x = X_all[i].reshape(1, -1)\n",
    "    y_true = y_all[i]\n",
    "\n",
    "    y_proba = model.predict_proba(x)[0]\n",
    "    y_pred = np.argmax(y_proba)\n",
    "    confidence = abs(y_proba[1] - y_proba[0])\n",
    "    \n",
    "    if len(recent_accuracies) >= window_size:\n",
    "        recent_accuracies.pop(0)\n",
    "    recent_accuracies.append(int(y_pred == y_true))\n",
    "\n",
    "    if len(recent_accuracies) == window_size:\n",
    "        avg_accuracy = np.mean(recent_accuracies)\n",
    "        if avg_accuracy < (1 - threshold_drop):\n",
    "            model.partial_fit(X_all[i-window_size:i], y_all[i-window_size:i])\n",
    "            recent_accuracies = []\n",
    "\n",
    "    if confidence > uncertainty_threshold:\n",
    "        model.partial_fit(x, [y_pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf61457e",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(model, 'fraud_detection_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e478060",
   "metadata": {},
   "source": [
    "**in Kernel Processing section**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0f5382",
   "metadata": {},
   "outputs": [],
   "source": [
    "G_loaded = Generator(noise_dim, n_features)\n",
    "D_loaded = Classifier(n_features)\n",
    "\n",
    "G_loaded.load_state_dict(torch.load('fraud_detection_G.pth'))\n",
    "D_loaded.load_state_dict(torch.load('fraud_detection_D.pth'))\n",
    "\n",
    "G_loaded.to(device)\n",
    "D_loaded.to(device)\n",
    "\n",
    "online_model = joblib.load('fraud_detection_model.pkl')\n",
    "scaler = StandardScaler()\n",
    "\n",
    "name = \"lr\"\n",
    "with open(f\"model_{name}.pkl\", \"rb\") as f:\n",
    "    basic_model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7523f385",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = basic_model\n",
    "def prep_val(model, f):\n",
    "    model.predict([f])[0]\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0eff6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = D_loaded\n",
    "def prep_val(model, f):\n",
    "    return model(torch.tensor(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a165ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "\n",
    "server = \"localhost\"\n",
    "database = \"db_02\"\n",
    "username = \"postgres\"\n",
    "password = \"ABcd@12#$\"\n",
    "source = \"creditcard_train\"\n",
    "\n",
    "try:\n",
    "  conn = psycopg2.connect(dbname=database, user=username, password=password, host=server, port=\"5432\", sslmode='disable')\n",
    "except psycopg2.Error as e:\n",
    "  print(\"Error connecting to PostgreSQL database:\", e)\n",
    "else:\n",
    "  print(\"Connection established successfully!\")\n",
    "\n",
    "cursor = conn.cursor()\n",
    "\n",
    "query =f\"SELECT * FROM {source}\"\n",
    "cursor.execute(query)\n",
    "rows = cursor.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755eb47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(row):\n",
    "    # data={}\n",
    "\n",
    "    # data['ID'] = row[0]\n",
    "    # data['Time']= row[1]\n",
    "    # for i in range (2,30):\n",
    "    #     data[f\"V{i-1}\"]= float(row[i])\n",
    "    # data['Amount']= row[30]\n",
    "\n",
    "    data = [float(x) for x in row[1:]]\n",
    "    data = [float(x) for x in row[1:-1]] # because creditcard_train.csv\n",
    "\n",
    "    # print(f\"\\r{row}\", end=\"\")\n",
    "    # return data\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2cfafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_event(row):\n",
    "    features = extract_features(row)\n",
    "    prediction = model.predict([features])[0]\n",
    "\n",
    "    # if prediction == 1:\n",
    "    #     print(f\"[ALERT] Fraud detected for event: {row[0]}\")\n",
    "    # else:\n",
    "    #     print(f\"[OK] Normal event: {row}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff3fdb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def monitor_sysmon_logs(upto=max(10000, len(rows))):\n",
    "    server = 'localhost'\n",
    "    log_type = 'Microsoft-Windows-Sysmon/Operational'\n",
    "    hand = win32evtlog.OpenEventLog(server, log_type)\n",
    "    \n",
    "    count = 0\n",
    "    s = time.time()\n",
    "    while True:\n",
    "        count += 1\n",
    "        events = win32evtlog.ReadEventLog(\n",
    "            hand,\n",
    "            win32evtlog.EVENTLOG_BACKWARDS_READ | win32evtlog.EVENTLOG_SEQUENTIAL_READ,\n",
    "            0\n",
    "        )\n",
    "        if not events:\n",
    "            break\n",
    "\n",
    "        for ev_obj in events:\n",
    "            if ev_obj.EventID in [1, 3, 11]:\n",
    "                if count >= len(rows):\n",
    "                    break\n",
    "                handle_event(rows[count])\n",
    "                count += 1\n",
    "                # time.sleep(0.1)\n",
    "        \n",
    "    return time.time() - s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44cc629",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_time = monitor_sysmon_logs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d09765e",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = time.time()\n",
    "for row in rows:\n",
    "    f = extract_features(row)\n",
    "    p = prep_val(model, f)\n",
    "u_time = time.time() - s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93340e70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3.2229907512664795, 17.734492540359497, 81.826)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_time, u_time, round((u_time - k_time) * 100 / u_time, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7891979c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
