{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from shap import Explainer\n",
    "import pickle\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection established successfully!\n"
     ]
    }
   ],
   "source": [
    "server = \"localhost\"\n",
    "database = \"db_02\"\n",
    "username = \"postgres\"\n",
    "password = \"ABcd@12#$\"\n",
    "source = \"creditcard_train\"\n",
    "\n",
    "data_train=[]\n",
    "\n",
    "try:\n",
    "  conn = psycopg2.connect(dbname=database, user=username, password=password, host=server, port=\"5432\", sslmode='disable')\n",
    "except psycopg2.Error as e:\n",
    "  print(\"Error connecting to PostgreSQL database:\", e)\n",
    "else:\n",
    "  print(\"Connection established successfully!\")\n",
    "\n",
    "cursor = conn.cursor()\n",
    "\n",
    "query =f\"SELECT * FROM {source}\"\n",
    "cursor.execute(query)\n",
    "\n",
    "for i in cursor.fetchall():\n",
    "  data_train.append(i[1:])\n",
    "\n",
    "column_names = ['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount', 'Class']\n",
    "data_train=pd.DataFrame(data_train, dtype=float, columns=column_names)\n",
    "# print(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Pre-Processing\n",
    "data_train = data_train.fillna(...)\n",
    "\n",
    "categorical_features = []\n",
    "\n",
    "if len(categorical_features) > 0:\n",
    "  encoder = LabelEncoder()\n",
    "  for feature in categorical_features:\n",
    "    data_train[feature] = encoder.fit_transform(data_train[feature])\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "features_to_scale = data_train.drop(\"Class\", axis=1).columns\n",
    "data_train_scaled = scaler.fit_transform(data_train[features_to_scale])\n",
    "\n",
    "X_train = data_train_scaled\n",
    "y_train = data_train[\"Class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(213605, 30) (213605,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Flatten(input_shape=(30,)),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(1, activation='sigmoid'),\n",
    "])\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 30)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               3968      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,289\n",
      "Trainable params: 12,289\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9982210154256689\n",
      "Confusion Matrix:\n",
      " [[213207      0]\n",
      " [   380     18]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00    213207\n",
      "         1.0       1.00      0.05      0.09       398\n",
      "\n",
      "    accuracy                           1.00    213605\n",
      "   macro avg       1.00      0.52      0.54    213605\n",
      "weighted avg       1.00      1.00      1.00    213605\n",
      "\n",
      "AUC-ROC: 0.5226130653266332\n"
     ]
    }
   ],
   "source": [
    "# basic deep learning network\n",
    "model.fit(X_train, y_train, epochs=10, verbose=0)\n",
    "y_pred = model.predict(X_train, verbose=0).astype(int)\n",
    "\n",
    "accuracy = accuracy_score(y_train, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "confusion_mat = confusion_matrix(y_train, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", confusion_mat)\n",
    "classification_rep = classification_report(y_train, y_pred)\n",
    "print(\"Classification Report:\\n\", classification_rep)\n",
    "roc_auc = roc_auc_score(y_train, y_pred)\n",
    "print(\"AUC-ROC:\", roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PermutationExplainer explainer:  80%|███████▉  | 170657/213605 [13:52:06<2:22:01,  5.04it/s] "
     ]
    }
   ],
   "source": [
    "explainer = Explainer(model, X_train)\n",
    "shap_values = explainer(X_train)\n",
    "\n",
    "with open(\"model_dl.pkl\", \"wb\") as f:\n",
    "    pickle.dump(model, f)\n",
    "\n",
    "with open(\"explainer_dl.pkl\", \"wb\") as f:\n",
    "    pickle.dump(explainer, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
